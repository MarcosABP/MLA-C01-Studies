{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96490230-2866-4102-9ca2-dd4516309182",
   "metadata": {},
   "source": [
    "# TD-IDF - Código para medir importância de uma palavra num documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3624daf1-1f69-4d14-8339-cb271eabd38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Importar subset da Wikipedia que está em bucket S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e44d43e-3540-4b91-ae9a-2c223e60f30c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-15T22:17:32.311864Z",
     "iopub.status.busy": "2025-09-15T22:17:32.311160Z",
     "iopub.status.idle": "2025-09-15T22:18:01.129261Z",
     "shell.execute_reply": "2025-09-15T22:18:01.128675Z",
     "shell.execute_reply.started": "2025-09-15T22:17:32.311831Z"
    },
    "executionRoleArn": "arn:aws:iam::904233096976:role/service-role/AmazonEMRStudio_RuntimeRole_1757969012559",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a6f7404f72a4818b7411ddf4e3ae0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr><th>ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>0</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"https://spark-live-ui.emr-serverless.amazonaws.com\" class=\"emr-proxy-link\" emr-runtime=\"emr-serverless\" emr-resource=\"00fvkd8h947l190e\" application-id=\"00fvkcmaot212t0d\">Link</a></td><td></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+-------------------+--------------------+\n",
      "|_c0|                 _c1|                _c2|                 _c3|\n",
      "+---+--------------------+-------------------+--------------------+\n",
      "| 12|           Anarchism|2008-12-30 06:23:05|Anarchism (someti...|\n",
      "| 25|              Autism|2008-12-24 20:41:05|Autism is a brain...|\n",
      "| 39|              Albedo|2008-12-29 18:19:09|The albedo of an ...|\n",
      "|290|                   A|2008-12-27 04:33:16|The letter A is t...|\n",
      "|303|             Alabama|2008-12-29 08:15:47|Alabama (formally...|\n",
      "|305|            Achilles|2008-12-30 06:18:01|thumb\\n\\nIn Greek...|\n",
      "|307|     Abraham Lincoln|2008-12-28 20:18:23|Abraham Lincoln (...|\n",
      "|308|           Aristotle|2008-12-29 23:54:48|Aristotle (Greek:...|\n",
      "|309|An American in Paris|2008-09-27 19:29:28|An American in Pa...|\n",
      "|324|       Academy Award|2008-12-28 17:50:43|The Academy Award...|\n",
      "|330|             Actrius|2008-05-23 15:24:32|Actrius (Actresse...|\n",
      "|332|     Animalia (book)|2008-12-18 11:12:34|thumbAnimalia (IS...|\n",
      "|334|International Ato...|2008-11-21 22:40:20|International Ato...|\n",
      "|336|            Altruism|2008-12-27 03:57:17|Altruism is selfl...|\n",
      "|339|            Ayn Rand|2008-12-30 08:03:06|Ayn Rand (,  – Ma...|\n",
      "|340|        Alain Connes|2008-09-03 13:41:39|Alain Connes (bor...|\n",
      "|344|          Allan Dwan|2008-11-14 05:28:58|Allan Dwan (April...|\n",
      "|358|             Algeria|2008-12-29 02:54:36|Algeria (, al-Jaz...|\n",
      "|359|List of character...|2008-12-23 20:20:21|This is a list of...|\n",
      "|569|        Anthropology|2008-12-28 23:04:30|Anthropology (, f...|\n",
      "+---+--------------------+-------------------+--------------------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "rawdata = spark.read.options(sep=\"\\t\").csv(\"s3://aws-emr-studio-904233096976-us-east-2/1757969012559/subset-small.tsv\")\n",
    "rawdata.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf8ded9-25a3-490b-9470-6fbcaf581a08",
   "metadata": {},
   "source": [
    "Como o dataset não tem nomes das colunas definidos, faremos manualmente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86430357-08a3-4b6a-89e3-0baef6931362",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "articles = rawdata.toDF(\"ID\", \"Title\", \"Time\", \"Document\")\n",
    "articles.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e98d68-381a-442b-b276-73cbeadade3e",
   "metadata": {},
   "source": [
    "Next we need to \"clean\" our data. We know TF/IDF can't handle null documents, so first let's check for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32588c28-fdc4-4389-8d5d-3065c8d37a3d",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "articles.filter(articles.Document.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a925d14-1225-4de1-982d-52056299549f",
   "metadata": {},
   "source": [
    "Looks like there is one null document. As there is only one and it's clearly corrupt when we look into it, we can just remove it and call it a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edc736d-fd9e-4114-9e9d-1d8d90cb985a",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleanedArticles = articles.filter(articles.Document.isNotNull())\n",
    "cleanedArticles.filter(articles.Document.isNull()).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a6112-640d-4e70-9590-2c300e676f0e",
   "metadata": {},
   "source": [
    "TF/IDF wants numbers, not words. So now we need to pre-process our data before we can run any fun algorithms on it. We'll first tokenize the articles to split them up into words, and store them in a sparse vector that is now a numeric representation of the words in each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74d52d-eca9-41eb-b771-1c20d226967b",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "\n",
    "tokenizer= Tokenizer(inputCol=\"Document\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(cleanedArticles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cff6d6-86d8-49b7-bc49-5e7e7bb70037",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
    "featurizedData = hashingTF.transform(wordsData)\n",
    "featurizedData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe626404-a76c-4a2c-b11b-5bbf31d62af9",
   "metadata": {},
   "source": [
    "That hashing operation basically computed term frequencies for us by storing how often each hashed word occured in each article. So we have TF, but we want TF/IDF scores for every term in every document. We'll store these final scores in a new column called \"features\", which is a sparse vector containing TF/IDF scores for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5fb92c-1fd3-48d8-b86e-0a9664dd4cee",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f452acfe-c743-4099-9411-04ed4a19f2d6",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "rescaledData.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e3c521-1542-4f23-9bb7-8217403aa5ff",
   "metadata": {},
   "source": [
    "So let's use this to do a search for the term \"Gettysburg\". Again, we need numbers, not words, so the first task is to get the hash value for \"Gettysburg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e0581-6a32-4ff8-b075-289128f77c98",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([StructField(\"words\", ArrayType(StringType()))])\n",
    "\n",
    "df = spark.createDataFrame(([[[\"gettysburg\"]]]), schema).toDF(\"words\")\n",
    "df.show()\n",
    "\n",
    "gettysburg = hashingTF.transform(df)\n",
    "gettysburg.show()\n",
    "\n",
    "featureVec = gettysburg.select('rawFeatures').collect()\n",
    "print(featureVec)\n",
    "\n",
    "gettysburgID = int(featureVec[0].rawFeatures.indices[0])\n",
    "print(gettysburgID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9ba586-90f0-4042-9605-4ec4503d217f",
   "metadata": {},
   "source": [
    "OK, we have the magic number that represents \"Gettysburg\". Now we can add another column - we'll call it \"score\" - that just extracts the TF/IDF value for Gettysburg for each document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093b7e6-9e6d-4469-a11f-85ebaf8ccd07",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "termExtractor = udf(lambda x: float(x[gettysburgID]), FloatType())\n",
    "gettysburgDF = rescaledData.withColumn('score', termExtractor(rescaledData.features))\n",
    "\n",
    "gettysburgDF.show()\n",
    "                                                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af4420e6-f6e2-4151-8ac1-ac35fba42040",
   "metadata": {},
   "source": [
    "Now all we have to do is sort our articles by score, and we'll have the most relevant articles for Gettysburg!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a93a5a-f2e3-48b9-b216-000b8361eee4",
   "metadata": {
    "executionRoleArn": "arn:aws:iam::159107795666:role/service-role/AmazonEMRStudio_RuntimeRole_1733157099735",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sortedResults = gettysburgDF.filter(\"score > 0\").orderBy('score', ascending=False).select('ID', 'Title', 'Document', 'score')\n",
    "sortedResults.show(truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ded2ec-47ed-4174-871a-70146083beb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "python",
   "name": "spark_magic_pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
